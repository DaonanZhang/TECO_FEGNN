{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16888f8-952f-401e-9b25-d0cbaae985f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init...\n",
      "Start training...\n",
      "{\n",
      "  \"agent_id\": \"00011\",\n",
      "  \"agent_dir\": \"./logs\",\n",
      "  \"origin_path\": \"./Dataset_res250_reg4c/\",\n",
      "  \"debug\": true,\n",
      "  \"bp\": false,\n",
      "  \"batch\": 16,\n",
      "  \"accumulation_steps\": 8,\n",
      "  \"test_batch\": 0,\n",
      "  \"es_mindelta\": 0.5,\n",
      "  \"num_features_in\": 10,\n",
      "  \"num_features_out\": 1,\n",
      "  \"emb_hidden_dim\": 256,\n",
      "  \"k\": 20,\n",
      "  \"conv_dim\": 256,\n",
      "  \"seed\": 1,\n",
      "  \"model\": \"PEGNN\",\n",
      "  \"fold\": 4,\n",
      "  \"holdout\": 1,\n",
      "  \"lowest_rank\": 1,\n",
      "  \"hp_marker\": \"tuned\",\n",
      "  \"nn_length\": 3,\n",
      "  \"nn_hidden_dim\": 32,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"d_model\": 32,\n",
      "  \"nhead\": 2,\n",
      "  \"dim_feedforward\": 128,\n",
      "  \"transformer_dropout\": 0.1,\n",
      "  \"num_encoder_layers\": 2,\n",
      "  \"env_features_in\": 11,\n",
      "  \"transformer_dec_output\": 32,\n",
      "  \"emb_dim\": 32,\n",
      "  \"epoch\": 1,\n",
      "  \"es_endure\": 5,\n",
      "  \"nn_lr\": 1e-05,\n",
      "  \"coffer_slot\": \"./coffer_kcn/000011/\",\n",
      "  \"tgt_op\": \"mcpm10\"\n",
      "}\n",
      "Working on CPU\n",
      "Length of df dict: 200\n",
      "Length of call list: 6656\n",
      "Length of df dict: 200\n",
      "Length of call list: 5632\n",
      "INTP_Model(\n",
      "  (conv1): GCNConv(10, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Training to 1 epochs (16 of mini batch size)\n",
      "Each epoch #real_iter: 52.0\n",
      "working on training loop\n",
      "total test: 352: 0.48131245002150536 - real_iter_time: 0.40645980834960943\n",
      "Test Done\n",
      "\t\t--------\n",
      "\t\tIter: 52, inter_train_loss: 26.044379644095898\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 2248.423095703125, last best test_loss: inf\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: 0.08679355783277651, MAE: 31.937828\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 1\n",
      "total test: 352s: 0.3384432066231966 - real_iter_time: 0.327311754226684573\n",
      "Test Done\n",
      "\t\t--------\n",
      "\t\tIter: 104, inter_train_loss: 20.966842276975513\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 1606.034423828125, last best test_loss: 2248.423095703125\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: 0.10984355398288645, MAE: 22.812988\n",
      "\t\t--------\n",
      "\n",
      "Current epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Start evaluation...\n",
      "Working on CPU\n",
      "Length of df dict: 200\n",
      "Length of call list: 1536\n",
      "\t\t--------\n",
      "\t\tr_squared: 0.31000856358609985, MAE: 2.3672464\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tDiffer: 4.215063095092773, count: 1536\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import support_functions\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"PEGNN\"))\n",
    "import json\n",
    "import time\n",
    "import myconfig_kcn as myconfig\n",
    "import solver_kcn as solver\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# rebuild the folder missed?\n",
    "def build_folder_and_clean(path):\n",
    "    check = os.path.exists(path)\n",
    "    if check:\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def train(job_id, settings):\n",
    "    result_sheet = []\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    list_total, list_err = solver.training(settings=settings, job_id=job_id)\n",
    "    print(\"Start evaluation...\")\n",
    "    best_err, r_squared = solver.evaluate(settings=settings, job_id=job_id)\n",
    "\n",
    "    result_sheet.append([list_total, list_err, best_err, r_squared])\n",
    "\n",
    "    # collect wandb result into file\n",
    "    rtn = {\n",
    "        \"best_err\": sum(result_sheet[0][2]) / len(result_sheet[0][2]),\n",
    "        \"r_squared\": sum(result_sheet[0][3]) / len(result_sheet[0][3]),\n",
    "        \"list_total_0\": result_sheet[0][0],\n",
    "        \"list_err_0\": result_sheet[0][1],\n",
    "    }\n",
    "\n",
    "    json_dump = json.dumps(rtn)\n",
    "    with open(settings['agent_dir'] + f'/{job_id}.rtn', 'w') as fresult:\n",
    "        fresult.write(json_dump)\n",
    "\n",
    "\n",
    "\n",
    "# RuntimeError: mat1 and mat2 shapes cannot be multiplied (2974x42 and 46x256)\n",
    "# problem for number of the dataset_size since i change the size into minimal size\n",
    "# but if this problem occurs in ssh server then means all right\n",
    "if __name__ == '__main__':\n",
    "    job_id = '000011'\n",
    "\n",
    "    print('Init...')\n",
    "\n",
    "    settings = {\n",
    "        'agent_id': '00011',\n",
    "        'agent_dir': './logs',\n",
    "        'origin_path': './Dataset_res250_reg4c/',\n",
    "\n",
    "        # debug mode=>data_set\n",
    "        'debug': True,\n",
    "        'bp': False,\n",
    "\n",
    "        # full_batch->batch->accumulation_steps double\n",
    "        'batch': 16,\n",
    "        'accumulation_steps': 128 // 16,\n",
    "        'test_batch': 0,\n",
    "\n",
    "        'es_mindelta': 0.5,\n",
    "\n",
    "        # 'num_features_in': 2,\n",
    "        'num_features_in': 10,\n",
    "\n",
    "        'num_features_out': 1,\n",
    "        'emb_hidden_dim': 256,\n",
    "        \n",
    "        'k': 20,\n",
    "        'conv_dim': 256,\n",
    "\n",
    "        'seed': 1,\n",
    "        'model': 'PEGNN',\n",
    "        'fold': 4,\n",
    "        'holdout': 1,\n",
    "        'lowest_rank': 1,\n",
    "\n",
    "        'hp_marker': 'tuned',\n",
    "        'nn_length': 3,\n",
    "        'nn_hidden_dim': 32,\n",
    "        'dropout_rate': 0.1,\n",
    "\n",
    "        # for transformer\n",
    "        'd_model': 32,\n",
    "        'nhead': 2,\n",
    "\n",
    "        'dim_feedforward': 128,\n",
    "        'transformer_dropout': 0.1,\n",
    "        'num_encoder_layers': 2,\n",
    "        'env_features_in': 11,\n",
    "\n",
    "        \n",
    "        'transformer_dec_output': 32,\n",
    "        'emb_dim': 32,\n",
    "        \n",
    "        'epoch': 1,\n",
    "        'es_endure': 5,\n",
    "        'nn_lr': 1e-5,\n",
    "    }\n",
    "\n",
    "    # build working folder\n",
    "    dt_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    coffer_slot = myconfig.coffer_path + str(job_id) + '/'\n",
    "\n",
    "    # missed\n",
    "    make_dir(coffer_slot)\n",
    "    build_folder_and_clean(coffer_slot)\n",
    "    settings['coffer_slot'] = coffer_slot\n",
    "    settings['tgt_op'] = 'mcpm10'\n",
    "\n",
    "    train(job_id, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18caa541-a87c-49f8-9e75-ae193ef85315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_3",
   "language": "python",
   "name": "ml_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
