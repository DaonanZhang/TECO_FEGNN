{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb6b3a3-ca42-47fd-85f2-631c58e2f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init...\n",
      "Start training...\n",
      "{\n",
      "  \"agent_id\": \"00001\",\n",
      "  \"agent_dir\": \"./logs\",\n",
      "  \"origin_path\": \"./Dataset_res250_reg4c/\",\n",
      "  \"debug\": true,\n",
      "  \"bp\": false,\n",
      "  \"batch\": 16,\n",
      "  \"accumulation_steps\": 8,\n",
      "  \"test_batch\": 0,\n",
      "  \"es_mindelta\": 0.5,\n",
      "  \"num_features_in\": 9,\n",
      "  \"num_features_out\": 1,\n",
      "  \"emb_hidden_dim\": 256,\n",
      "  \"k\": 20,\n",
      "  \"conv_dim\": 256,\n",
      "  \"seed\": 1,\n",
      "  \"model\": \"PEGNN\",\n",
      "  \"fold\": 4,\n",
      "  \"holdout\": 1,\n",
      "  \"lowest_rank\": 1,\n",
      "  \"hp_marker\": \"tuned\",\n",
      "  \"nn_length\": 3,\n",
      "  \"nn_hidden_dim\": 32,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"d_model\": 32,\n",
      "  \"nhead\": 2,\n",
      "  \"dim_feedforward\": 128,\n",
      "  \"transformer_dropout\": 0.1,\n",
      "  \"num_encoder_layers\": 2,\n",
      "  \"env_features_in\": 11,\n",
      "  \"transformer_dec_output\": 32,\n",
      "  \"emb_dim\": 32,\n",
      "  \"epoch\": 3,\n",
      "  \"es_endure\": 5,\n",
      "  \"nn_lr\": 1e-05,\n",
      "  \"aux_task_num\": 1,\n",
      "  \"hyper_lr\": 1e-05,\n",
      "  \"hyper_decay\": 0.0,\n",
      "  \"hyper_interval\": 20,\n",
      "  \"hyper_aux_loss_weight\": 0.001,\n",
      "  \"heads_nn_length\": 2,\n",
      "  \"heads_nn_hidden_dim\": 64,\n",
      "  \"heads_dropout_rate\": 0.1,\n",
      "  \"coffer_slot\": \"./coffer_al_only/000006/\",\n",
      "  \"tgt_op\": \"mcpm10\"\n",
      "}\n",
      "Working on CPU\n",
      "Length of df dict: 100\n",
      "Length of call list: 2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df dict: 100\n",
      "Length of call list: 2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df dict: 1205\n",
      "Length of call list: 30976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df dict: 100\n",
      "Length of call list: 3072\n",
      "name: spenc.ffn.layers.0.linear.weight, param: torch.Size([256, 64])\n",
      "name: spenc.ffn.layers.0.linear.bias, param: torch.Size([256])\n",
      "name: spdec.0.weight, param: torch.Size([128, 256])\n",
      "name: spdec.0.bias, param: torch.Size([128])\n",
      "name: spdec.2.weight, param: torch.Size([64, 128])\n",
      "name: spdec.2.bias, param: torch.Size([64])\n",
      "name: spdec.4.weight, param: torch.Size([32, 64])\n",
      "name: spdec.4.bias, param: torch.Size([32])\n",
      "name: conv1.bias, param: torch.Size([256])\n",
      "name: conv1.lin.weight, param: torch.Size([256, 41])\n",
      "name: conv2.bias, param: torch.Size([256])\n",
      "name: conv2.lin.weight, param: torch.Size([256, 256])\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 2, 9: 2, 10: 3, 11: 3}\n",
      "PEGCN(\n",
      "  (spenc): GridCellSpatialRelationEncoder(\n",
      "    (ffn): MultiLayerFeedForwardNN(\n",
      "      (layers): ModuleList(\n",
      "        (0): SingleFeedForwardNN(\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (act): ReLU()\n",
      "          (linear): Linear(in_features=64, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (spdec): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      "  (conv1): GCNConv(41, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (task_heads): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Training to 3 epochs (16 of mini batch size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each epoch #real_iter: 18.0\n",
      "working on training loop\n",
      "Start Evaluation 0.17973297834396362 Aux_loss:[7.263245788635686e-05] - real_iter_time: 1.6361680030822754\n",
      "\t\t--------\n",
      "\t\tIter: 18, inter_train_loss: 3.9892451763153076\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tIter: 18, inter_aux_loss: [0.0012667598202824593]\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 413.4653015136719, last best test_loss: inf\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: -5.200649058384271, MSE: 29.349379\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Evaluation 0.11225584894418716 Aux_loss:[6.749433669028804e-05] - real_iter_time: 0.45812416076660156\n",
      "\t\t--------\n",
      "\t\tIter: 36, inter_train_loss: 2.656019926071167\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tIter: 36, inter_aux_loss: [0.0011964954901486635]\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 217.3418731689453, last best test_loss: 413.4653015136719\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: -2.259428761539274, MSE: 21.278994\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Evaluation 0.08269195258617401 Aux_loss:[5.745437738369219e-05] - real_iter_time: 0.51339459419250498\n",
      "\t\t--------\n",
      "\t\tIter: 54, inter_train_loss: 1.8878557682037354\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tIter: 54, inter_aux_loss: [0.0011419253423810005]\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 119.32720947265625, last best test_loss: 217.3418731689453\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: -0.7895241964518545, MSE: 15.767002\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Evaluation 0.06577761471271515 Aux_loss:[4.480565257836133e-05] - real_iter_time: 0.57837843894958523\n",
      "\t\t--------\n",
      "\t\tIter: 72, inter_train_loss: 1.3266254663467407\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tIter: 72, inter_aux_loss: [0.0010283681331202388]\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\ttest_loss: 83.69699096679688, last best test_loss: 119.32720947265625\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tr_squared: -0.25518562415411195, MSE: 13.204875\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Start evaluation...\n",
      "Working on CPU\n",
      "Length of df dict: 100\n",
      "Length of call list: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t--------\n",
      "\t\tr_squared: -81.17395685648698, MSE: 20.920858\n",
      "\t\t--------\n",
      "\n",
      "\t\t--------\n",
      "\t\tDiffer: 18.136117935180664, count: 512\n",
      "\t\t--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = self._density_vmin(array)\n",
      "/home/kit/stud/uqqww/.local/lib/python3.9/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = self._density_vmax(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import support_functions\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"PEGNN\"))\n",
    "import json\n",
    "import time\n",
    "import myconfig_al_only as myconfig\n",
    "import solver_al_only as solver\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# rebuild the folder missed?\n",
    "def build_folder_and_clean(path):\n",
    "    check = os.path.exists(path)\n",
    "    if check:\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def train(job_id, settings):\n",
    "    result_sheet = []\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    list_total, list_err = solver.training(settings=settings, job_id=job_id)\n",
    "    print(\"Start evaluation...\")\n",
    "    best_err, r_squared = solver.evaluate(settings=settings, job_id=job_id)\n",
    "\n",
    "    result_sheet.append([list_total, list_err, best_err, r_squared])\n",
    "\n",
    "    # collect wandb result into file\n",
    "    rtn = {\n",
    "        \"best_err\": sum(result_sheet[0][2]) / len(result_sheet[0][2]),\n",
    "        \"r_squared\": sum(result_sheet[0][3]) / len(result_sheet[0][3]),\n",
    "        \"list_total_0\": result_sheet[0][0],\n",
    "        \"list_err_0\": result_sheet[0][1],\n",
    "    }\n",
    "\n",
    "    json_dump = json.dumps(rtn)\n",
    "    with open(settings['agent_dir'] + f'/{job_id}.rtn', 'w') as fresult:\n",
    "        fresult.write(json_dump)\n",
    "\n",
    "\n",
    "\n",
    "# RuntimeError: mat1 and mat2 shapes cannot be multiplied (2974x42 and 46x256)\n",
    "# problem for number of the dataset_size since i change the size into minimal size\n",
    "# but if this problem occurs in ssh server then means all right\n",
    "if __name__ == '__main__':\n",
    "    job_id = '000006'\n",
    "\n",
    "    print('Init...')\n",
    "\n",
    "    settings = {\n",
    "        'agent_id': '00001',\n",
    "        'agent_dir': './logs',\n",
    "        'origin_path': './Dataset_res250_reg4c/',\n",
    "\n",
    "        # debug mode=>data_set\n",
    "        'debug': True,\n",
    "        'bp': False,\n",
    "\n",
    "        # full_batch->batch->accumulation_steps double\n",
    "        'batch': 16,\n",
    "        'accumulation_steps': 128 // 16,\n",
    "        'test_batch': 0,\n",
    "\n",
    "        'es_mindelta': 0.5,\n",
    "\n",
    "        # 'num_features_in': 14,\n",
    "        'num_features_in': 9,\n",
    "\n",
    "        'num_features_out': 1,\n",
    "        'emb_hidden_dim': 256,\n",
    "        \n",
    "        'k': 20,\n",
    "        'conv_dim': 256,\n",
    "\n",
    "        'seed': 1,\n",
    "        'model': 'PEGNN',\n",
    "        'fold': 4,\n",
    "        'holdout': 1,\n",
    "        'lowest_rank': 1,\n",
    "\n",
    "        'hp_marker': 'tuned',\n",
    "        'nn_length': 3,\n",
    "        'nn_hidden_dim': 32,\n",
    "        'dropout_rate': 0.1,\n",
    "\n",
    "        # for transformer\n",
    "        'd_model': 32,\n",
    "        'nhead': 2,\n",
    "\n",
    "        'dim_feedforward': 128,\n",
    "        'transformer_dropout': 0.1,\n",
    "        'num_encoder_layers': 2,\n",
    "        'env_features_in': 11,\n",
    "\n",
    "        \n",
    "        'transformer_dec_output': 32,\n",
    "        'emb_dim': 32,\n",
    "        'epoch': 3,\n",
    "        'es_endure': 5,\n",
    "        'nn_lr': 1e-5,\n",
    "\n",
    "        \n",
    "        'aux_task_num': 1,\n",
    "        \n",
    "        # ----MAOAL----\n",
    "        'hyper_lr': 1e-5,\n",
    "        'hyper_decay': 0.0,\n",
    "        'hyper_interval': 20,\n",
    "        'hyper_aux_loss_weight': 0.001,\n",
    "\n",
    "        # ----Task heads----\n",
    "        'heads_nn_length': 2,\n",
    "        'heads_nn_hidden_dim': 64,\n",
    "        'heads_dropout_rate': 0.1,\n",
    "        \n",
    "    }\n",
    "\n",
    "    # build working folder\n",
    "    dt_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    coffer_slot = myconfig.coffer_path + str(job_id) + '/'\n",
    "\n",
    "    # missed\n",
    "    make_dir(coffer_slot)\n",
    "    build_folder_and_clean(coffer_slot)\n",
    "    settings['coffer_slot'] = coffer_slot\n",
    "    settings['tgt_op'] = 'mcpm10'\n",
    "\n",
    "    train(job_id, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e90ac-8705-4ca1-a3e5-cd0f39595d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893460a4-12d8-4654-b001-f7b0dc3aca66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_3",
   "language": "python",
   "name": "ml_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
